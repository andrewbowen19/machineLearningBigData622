---
title: 'DATA 622: Homework 2'
author: "Andrew Bowen"
date: "2024-03-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r cars}
library(tidyverse)
library(caret)
library(tidymodels)
library(GGally)
library(corrplot)
```


**For this assignment, our classification task will be to try to predict whether the home team or away team will win a given NFL game, based on the respective ELO ratings prior to the game, along with other features included in the Kaggle dataset.**

We'll be using the NFL ELO rating dataset we used in homework 1. [This dataset](https://www.kaggle.com/datasets/dtrade84/nfl-elo-ratings) comes from Kaggle, and contains the [ELO ratings](https://en.wikipedia.org/wiki/Elo_rating_system) of NFL teams both before and after their matchups, as well as the points scored by each team in the game. More information on the FiveThirtyEight method which calculates these ELO ratings can be [found here](https://fivethirtyeight.com/methodology/how-our-nfl-predictions-work/).
```{r warning=FALSE, message=FALSE}
elo <- read_csv("data/nfl_elo.csv")

# Some basic handling of team renames, as well as a boolean winner column
elo <- elo %>% 
  mutate(team1 = ifelse(team1=="WSH", "WAS", team1),
         team2 = ifelse(team2=="WSH", "WAS", team2),
         winner = ifelse(score1 > score2, "Home", "Away"))

elo$winner <- as.factor(elo$winner)
```

## Exploratory Data Analysis

First, let's take a quick look at the distribution of pre-game ELO ratings of each team (home & away):
```{r}
prelo1 <- elo %>% 
  rename(elo = elo1_pre, team=team1) %>%
  select(c("team", "elo")) %>%
  mutate(team_type = "Home Team") 
prelo2 <- elo %>%
  rename(elo = elo2_pre, team=team2) %>%
  select(c("team", "elo")) %>%
  mutate(team_type = "Away Team")
prelo <- rbind(prelo1, prelo2)

# Plot pre-game ELO ratings for home and away teams
ggplot(prelo, aes(elo, fill = team_type)) +
  geom_density(alpha = 0.2) +
  labs(x="ELO Rating (pre-game)", title="Pre-Matchup ELO Ratings of NFL Teams (post-1967)")
```

Both our distributions of pre-game ELO ratings for home and away teams look relatively normally distributed. This is helpful to know before we go into modeling, as some modeling algorithms expect normally distributed (and sometimes scaled & centered) data.

Let's also take a look at the pair plot of our joint distribuions

```{r warning=FALSE, message=FALSE}

elo %>% select(winner, elo1_pre, elo2_pre, elo_prob1, elo_prob2, qbelo1_pre, qbelo2_pre) %>%
  ggpairs()
```
```{r}
elo %>% mutate(winner=ifelse(winner== "Home", 1, 0)) %>% select(winner, elo1_pre, elo2_pre, elo_prob1, elo_prob2, qbelo1_pre, qbelo2_pre) %>% cor() %>% corrplot()
```

```{r}
freq.na(elo)
```

We see from our NA frequency table

```{r}
qb_ratings <- elo[, c("qbelo1_pre", "qbelo2_pre") ]
imputed_qb_ratings <- mice(qb_ratings, meth='pmm')
qbRatingsImputed <- complete(imputed_qb_ratings, 1)
# Add imputed columns to dataframe
elo$qbelo1_pre <- qbRatingsImputed$qbelo1_pre
elo$qbelo2_pre <- qbRatingsImputed$qbelo2_pre
```

### Training-Test Split
Before we model our data using a decision tree, we'll need to create a training-test split for later validation. We'll hold out 20% of our dataset for testing.
```{r}
#make this example reproducible
set.seed(1234)

#create ID column
elo$game_id <- 1:nrow(elo)

#use 70% of dataset as traininging set and 30% as test set 
training <- elo %>% dplyr::sample_frac(0.80)
test  <- dplyr::anti_join(elo, training, by = 'game_id')
```





## Building Models
We can build a decision tree in R using the `tidymodels` library using the `decision_tree` function. 
```{r}
tree_spec <- decision_tree() %>%
 set_engine("rpart") %>%
 set_mode("classification")

# Fit the decision tree to the data using all properties
naive_model_formula <- winner ~ elo1_pre + elo2_pre + elo_prob1 + elo_prob2  + qbelo1_pre + qbelo2_pre + qb1_value_pre + qb2_value_pre + qb1_adj + qb2_adj + qbelo1_pre + qbelo2_pre
tree_fit <- tree_spec %>%
 fit(naive_model_formula, data = training)

summary(tree_fit)
# predictions <-predict(tree_fit, test)
```

Now we can use the naive decision tree model we built above and try to predict on our test set. We can also print out the confusion matrix of our predictions.
```{r}
# Predict winners in test set
predictions <- predict(tree_fit, test)

test$prediction <- as.factor(predictions$.pred_class)

# Print out confusion matrix
conf_mat(test, winner, prediction)
```

```{r}
# Train decision
tree <- caret::train(naive_model_formula, 
                     data=training, 
                     method="rpart", 
                     trControl = trainControl(method = "cv", number=10), na.action  = na.pass)
```


```{r}
simple_formula <- winner ~ elo1_pre + elo2_pre +  qbelo1_pre + qbelo2_pre#  + elo_prob1 + elo_prob2

tree_simple <- caret::train(simple_formula, 
                     data=training, 
                     method="rpart", 
                     trControl = trainControl(method = "cv", number=10))

```

## Evalutaion

One advantage of decision trees from the [pre-work article](https://decizone.com/blog/the-good-the-bad-the-ugly-of-using-decision-trees) is the idea of explainability. That is, decision trees are an explainable model because they often mirror the if-else logic of human decision making, even if conditional probabilities are used. Conversely, random forest methods will tend to improve the performance of a model, as they combine the "wisdom" of several weak learners (decision trees). However, these random forest models often **lose out** on explainability, since they are an amalgamation of several models together, each with a different structure.

One simple way to evaluate our decision trees is via a confusion matrix, which shows the relative counts of true and false positives and negatives. In our case, an `Away` team winning would be considered a member of the "positive" class, while a `Home` team victory would be a negative class instance. it shoudl be noted there's nothing inherently "positive" or "negative" about these outcomes, they are simply an artifact of the classification task at hand.
```{r}
confusionMatrisx(tree)
```


```{r simple-tree-conf-matrix}
confusionMatrix(tree_simple)
```


